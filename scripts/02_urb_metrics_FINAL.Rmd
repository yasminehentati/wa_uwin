---
title: "02a_urb_metrics_FINAL"
output: html_document
date: "2024-09-18"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Packages 
```{r}
library(pacman)
p_load(dplyr,here,sf,devtools,mapview,here,remotes,tidycensus,crsuggest,
       tidyr,terra,spatialEco,readr,ggfortify,rgeos,exactextractr,
       spatstat,spdep,landscapemetrics,tmap,viridis,gghighlight)

```

## Read in data 
```{r}
# load all sites
all_sites <- read.csv(here("data", "wa_counts.csv"), stringsAsFactors = FALSE)

# order data by Location Name 
all_sites <- all_sites[order(all_sites$site),]

# create new column for utm zone 

# transform into UTM - WA
all_sites <- st_as_sf(all_sites, coords=c("long", "lat"), crs="EPSG:4326")
#all_sites <- st_transform(all_sites, crs = "EPSG:32610")
#plot(all_sites)
mapview(all_sites)

# use utm for geometry
all_sites <- all_sites %>%
  st_transform("+proj=utm +zone=10 +datum=WGS84 +units=m")


head(all_sites)
# only keep 1 row for each site 
points_wa <- all_sites %>% distinct(site, .keep_all = TRUE) 

# check that it looks ok
mapview(points_wa)

#st_write(points_wa, here("data", "cameras", "points_wa.shp"),
 #     append = FALSE)

# correct projection
sites <- points_wa %>% st_transform(crs = "EPSG:32610")

```

## Calculate site values for population density 
```{r}
################################################################################
## HOUSING DENSITY DATA 
## read in housing density  data - starting with WA 
# data from: Silvis lab https://silvis.forest.wisc.edu/data/housing-block-change/
# Using 2020 data

wa_housing <- st_read(here("data", "housing_maps", 
                           "WA_block20_change_1990_2020_PLA4.shp"))

# filter to only king and pierce county
colnames(wa_housing)
wa_housing <- wa_housing %>% dplyr::filter(substr(BLK20, 1, 5) 
                                           %in% c("53033", "53053")) # king & pierce counties

# we only need 2010 housing data - select relevant info
wa_housing <- wa_housing %>% dplyr::select(BLK20, WATER20, POP2020,
                                           POPDEN2020, HUDEN2020,
                                           Shape_Leng:geometry)

# crop to actual study area 
sf_use_s2(FALSE)
wa_housing <- st_transform(wa_housing, crs=4326)
wa_housing <- st_crop(wa_housing, c(xmin= -121.7, ymin = 46.7, xmax = -122.8, ymax = 47.8))

st_write(wa_housing, here("data", "housing_maps", "wa_urban_huden_2020.shp"),
    append = FALSE)


# let's make all polygons with water (WATER20) NA so they don't get 
# counted in the calculation (otherwise will show up at pop den 0)
wa_housing <- wa_housing %>%
  mutate(POPDEN2020 = ifelse(WATER20 == 1, NA, POPDEN2020))


## now rasterize & calculate site housing density 

# rasterize the data
st_transform(wa_housing, crs = "EPSG:32610")  
template <- rast(ext(wa_housing), resolution=100, crs="EPSG:32610")
rast <- terra::rasterize(vect(wa_housing), template, field = "POPDEN2020")

# initialize new col for data
housing_dat <- st_drop_geometry(sites) %>%
  dplyr::mutate(POPDEN2020 = NA_real_)

# set buffer radius
buffer_radius <- 1000

Sys.time()

for (i in 1:nrow(sites)) {
  pt <- sites[i, ]  # iterate through sites 
  
  # create buffer
  buff <- vect(st_transform(pt, crs(rast)))
  buff_terra <- terra::buffer(buff, width = buffer_radius) 
  
  # need to give it a bit extra extent 
  buff_ext <- ext(buff_terra) 
  buff_ext <- ext(c(
    xmin = buff_ext$xmin - 1000,
    xmax = buff_ext$xmax + 1000,
    ymin = buff_ext$ymin - 1000,
    ymax = buff_ext$ymax + 1000))
  buff_terra <- crop(buff_terra, buff_ext)
  
  # crop and mask the raster 
  rast_cropped <- crop(rast, buff_terra)
  rast_masked <- terra::mask(rast_cropped, buff_terra)
  
  # xxtract values within the buffer, calculate mean
  extracted_value <- exact_extract(rast_masked, st_as_sf(buff_terra), fun = "mean", 
                                   weights = "area")
  housing_dat$POPDEN2020[i] <- extracted_value
  
  
  # Plot the results
  
  p <- ggplot() +
    geom_raster(rast_cropped, mapping = aes(x = x, y = y, fill = POPDEN2020)) +
    #   scale_fill_manual() +
    geom_sf(data = st_as_sf(buff_terra), fill = NA, color = "red", size = 1) +
    geom_sf(data = sites[i,], color = "blue", size = 3) +
    coord_sf(crs = st_crs(rast), datum = st_crs(rast)) +
    labs(title = paste("Site:", i),
         x = "Easting (m)", y = "Northing (m)",
         fill = "Raster Value") +
    theme_minimal()
  
  # Save the plot
  # ggsave(filename = paste0("plots/plot_site_", i, ".png"), plot = p, width = 8, height = 6)
  print(p) 
  Sys.sleep(2)
  print(i)
}

Sys.time()

# Check the final results
print(housing_dat)


write_csv(housing_dat, here("data", "covariates", "housing_dat.csv"))
```


## Calculate site values for impervious surface 
Code adapted from Jeff Haight 
```{r}
# NLCD landcover 
nalc <- rast("data/landcover/USA_NALCMS_landcover_2015v3_30m.tif") %>%
  crop(ext(wa_housing)) %>% terra::project("EPSG:32610")

# impervious surface cover for the Contiguous US
is <-rast("data/NLCD_imp/nlcd_2019_impervious_descriptor_l48_20210604.img") %>%
  crop(ext(wa_housing)) %>% terra::project("EPSG:32610")

is_dat <- st_drop_geometry(sites) %>%
  dplyr::mutate(Impervious = NA_real_)

# set buffer radius
buffer_radius <- 500

Sys.time()

for (i in 1:nrow(sites)) {
  pt <- sites[i, ]  # iterate through sites 
  
  # create buffer
  buff <- vect(st_transform(pt, crs(is)))
  buff_terra <- terra::buffer(buff, width = buffer_radius) 
  
  # need to give it a bit extra extent 
  buff_ext <- ext(buff_terra) 
  buff_ext <- ext(c(
    xmin = buff_ext$xmin - 1000,
    xmax = buff_ext$xmax + 1000,
    ymin = buff_ext$ymin - 1000,
    ymax = buff_ext$ymax + 1000))
  buff_terra <- crop(buff_terra, buff_ext)
  
  # crop and mask the raster 
  rast_cropped <- crop(is, buff_terra)
  rast_masked <- terra::mask(rast_cropped, buff_terra)
  
  # xxtract values within the buffer, calculate mean
  extracted_value <- exact_extract(rast_masked, st_as_sf(buff_terra), fun = "mean", 
                                   weights = "area")
  is_dat$Impervious[i] <- extracted_value
  
  
  # Plot the results
  
  p <- ggplot() +
    geom_raster(rast_cropped, mapping = aes(x = x, y = y, fill = Impervious)) +
    #   scale_fill_manual() +
    geom_sf(data = st_as_sf(buff_terra), fill = NA, color = "red", size = 1) +
    geom_sf(data = sites[i,], color = "blue", size = 3) +
    coord_sf(crs = st_crs(rast), datum = st_crs(rast)) +
    labs(title = paste("Site:", i),
         x = "Easting (m)", y = "Northing (m)",
         fill = "Raster Value") +
    theme_minimal()
  
  # Save the plot
  # ggsave(filename = paste0("plots/plot_site_", i, ".png"), plot = p, width = 8, height = 6)
  print(p) 
  Sys.sleep(2)
  print(i)
}

Sys.time()

# Check the final results
print(is_dat)


write_csv(is_dat, here("data", "covariates", "is_dat.csv"))

```

## Land cover categories + landscape metrics
Code adapted from Jeff Haight
```{r}

# directions on how to reclassify land cover categories
m <- c(1, 20,  # set all the natural land cover types to 20
       2, 20,
       3, 20,
       4, 20,
       5, 20,
       6, 20,
       7, 20,
       8, 20,
       9, 20,
       10, 20,
       11, 20,
       12, 20,
       13, 20,
       14, 20,
       16, 20)

start_time <- Sys.time()

for(i in 1:nsite){
  pt <- sites[i,]                                         # select a point
  buff <- vect(st_transform(pt, crs(nalc)))
  buff <- terra::buffer(buff, width = buffer_radius) 
  
  # need to give it a bit extra extent 
  buff_ext <- ext(buff) 
  buff_ext <- ext(c(
    xmin = buff_ext$xmin - 1000,
    xmax = buff_ext$xmax + 1000,
    ymin = buff_ext$ymin - 1000,
    ymax = buff_ext$ymax + 1000))
  buff <- crop(buff, buff_ext)
  
  # crop/mask raster
  ls_pre <- nalc %>%
    crop(buff) %>%
    mask(buff)
  
  ##### Calculate the first set of metrics
  # No reclassification necessary
  ca <- lsm_c_ca(ls_pre)        
  
  #plot(ls); plot(pt, add = T)   # plot (very optional)
  
  # Proportional area of each land cover class for each 
  # filter out the the data for each metric
  # convert from hectares to m^2 and calculate cover proportion based on buffer (10000 m^2/hectare / pi*r^2 square meters)
  # add to original array/matrix only if there is a value for that land cover class to add]
  
  # Temperate needleleaf (evergreen) forest
  lsm_type <- ca %>%                               
    filter(class == 1)
  if(length(lsm_type$value) > 0){
    metrics_comp[i,1] <- lsm_type$value/sum(ca$value)
  }
  
  # repeat for each land cover class
  # Subpolar taiga needleleaf (evergreen) forest
  lsm_type <- ca %>%                              
    filter(class == 2)
  if(length(lsm_type$value) > 0){
    metrics_comp[i,2] <- lsm_type$value/sum(ca$value)
  }
  
  # Tropical and sub-tropical evergreen broadleaf forest
  lsm_type <- ca %>%                              
    filter(class == 3)
  if(length(lsm_type$value) > 0){
    metrics_comp[i,3] <- lsm_type$value/sum(ca$value)
  }
  # Tropical and sub-tropical deciduous broadleaf forest
  lsm_type <- ca %>%                              
    filter(class == 4)
  if(length(lsm_type$value) > 0){
    metrics_comp[i,4] <- lsm_type$value/sum(ca$value)
  }
  
  # Temperate deciduous broadleaf forest
  lsm_type <- ca %>%                              
    filter(class == 5)
  if(length(lsm_type$value) > 0){
    metrics_comp[i,5] <- lsm_type$value/sum(ca$value)
  }
  
  # Mixed forest
  lsm_type <- ca %>%                              
    filter(class == 6)
  if(length(lsm_type$value) > 0){
    metrics_comp[i,6] <- lsm_type$value/sum(ca$value)
  }
  
  # Shrubland, tropical
  lsm_type <- ca %>%                              
    filter(class == 7)
  if(length(lsm_type$value) > 0){
    metrics_comp[i,7] <- lsm_type$value/sum(ca$value)
  }
  
  # Shrubland, temperate
  lsm_type <- ca %>%                              
    filter(class == 8)
  if(length(lsm_type$value) > 0){
    metrics_comp[i,8] <- lsm_type$value/sum(ca$value)
  }
  
  # Grassland, tropical
  lsm_type <- ca %>%                              
    filter(class == 9)
  if(length(lsm_type$value) > 0){
    metrics_comp[i,9] <- lsm_type$value/sum(ca$value)
  }
  
  # Grassland, temperate
  lsm_type <- ca %>%                              
    filter(class == 10)
  if(length(lsm_type$value) > 0){
    metrics_comp[i,10] <- lsm_type$value/sum(ca$value)
  }
  
  
  # Shrubland, polar lichen-moss
  lsm_type <- ca %>%                              
    filter(class == 11)
  if(length(lsm_type$value) > 0){
    metrics_comp[i,11] <- lsm_type$value/sum(ca$value)
  }
  
  # Grassland, polar lichen-moss
  lsm_type <- ca %>%                              
    filter(class == 12)
  if(length(lsm_type$value) > 0){
    metrics_comp[i,12] <- lsm_type$value/sum(ca$value)
  }
  
  # Barren, polar lichen-moss
  lsm_type <- ca %>%                              
    filter(class == 13)
  if(length(lsm_type$value) > 0){
    metrics_comp[i,13] <- lsm_type$value/sum(ca$value)
  }
  
  # Wetland
  lsm_type <- ca %>%                              
    filter(class == 14)
  if(length(lsm_type$value) > 0){
    metrics_comp[i,14] <- lsm_type$value/sum(ca$value)
  }
  
  # Cropland
  lsm_type <- ca %>%                              
    filter(class == 15)
  if(length(lsm_type$value) > 0){
    metrics_comp[i,15] <- lsm_type$value/sum(ca$value)
  }
  
  # Barren
  lsm_type <- ca %>%                              
    filter(class == 16)
  if(length(lsm_type$value) > 0){
    metrics_comp[i,16] <- lsm_type$value/sum(ca$value)
  }
  
  # Urban
  lsm_type <- ca %>%                              
    filter(class == 17)
  if(length(lsm_type$value) > 0){
    metrics_comp[i,17] <- lsm_type$value/sum(ca$value)
  }
  
  # Water
  lsm_type <- ca %>%                              
    filter(class == 18)
  if(length(lsm_type$value) > 0){
    metrics_comp[i,18] <- lsm_type$value/sum(ca$value)
  }
  
  # Ice and snow
  lsm_type <- ca %>%                              
    filter(class == 19)
  if(length(lsm_type$value) > 0){
    metrics_comp[i,19] <- lsm_type$value/sum(ca$value)
  }
  
  
  ##### Calculate next set of metrics
  # Reclassify, setting all the natural land cover types to 20
  m <- c(1, 20, 2, 20, 3, 20, 4, 20, 5, 20,
         6, 20, 7, 20, 8, 20, 9, 20, 10, 20,
         11, 20, 12, 20, 13, 20, 14, 20, 16, 20
  )
  rcmat <- matrix(m, ncol = 2, byrow = TRUE)
  
  ls <- reclassify(ls_pre, rcmat)
  
  
  # Class-level metrics
  mpa <- lsm_c_area_mn(ls)   # Mean patch size/area for each class (land cover group), in hectares
  pd <- lsm_c_pd(ls)         # Patch density for each class
  ed <- lsm_c_ed(ls)         # Edge density for each class
  enn <- lsm_c_enn_mn(ls)   # Mean Euclidean nearest-neighbor distance ('overall patch isolation')
  
  
  # Mean patch area for the natural patches
  lsm_type <- mpa %>%                               
    filter(class == 20)
  if(length(lsm_type$value) > 0){
    metrics_conf[i,1] <- lsm_type$value
  }
  
  # Patch density of natural patches
  lsm_type <- pd %>%                               
    filter(class == 20)
  if(length(lsm_type$value) > 0){
    metrics_conf[i,2] <- lsm_type$value
  }
  
  # Edge density of natural patches
  lsm_type <- ed %>%                               
    filter(class == 20)
  if(length(lsm_type$value) > 0){
    metrics_conf[i,3] <- lsm_type$value
  }
  
  # Overall isolation of natural patches
  lsm_type <- enn %>%                               
    filter(class == 20)
  if(length(lsm_type$value) > 0){
    metrics_conf[i,4] <- lsm_type$value
  }
  
  
  
  # Landscape-level metrics
  sdhi <- lsm_l_shdi(ls)     # Shannon's index for patch diversity
  metrics_conf[i,5] <- sdhi$value
  
  #plot(ls); plot(pt, add = T)   # plot (very optional)
  
  #print(i)
  #print(sites[i,]$site)  
}

end_time <- Sys.time()
end_time <- Sys.time()

elapsed_time <- difftime(end_time, start_time, units='mins')
cat(paste(paste('Metrics calculated in ', elapsed_time, sep=''), ' minutes', sep=''))

```

## Calculate relationships between landscape metrics 
Code adapted from Jeff Haight 
### Did not run this 
```{r}


##### RELATIUONSHIPS BETWEEN lANDSCAPE METRICS

library(ggcorrplot)
library(GGally)

data_ls <- read.csv("data/covariates/sitecov_landscapemetrics_1000m_sewatawa_allsites.csv", header = TRUE)
data_ls$ice <- as.numeric(data_ls$ice)    # 'ice' should be a proportion like the rest, even though that proportion is 0

#landscape_correlations <- round(cor(data_ls[,c(8,10:27)], use = "complete.obs"), 1)
landscape_correlations <- cor(data_ls[,c(8,10:27)], use = "complete.obs")
ggcorrplot(landscape_correlations, 
           #method = "circle", 
           #hc.order = TRUE, 
           type = "lower",
           outline.col = "white", 
           lab = TRUE, 
           digits = 1) +
  ggplot2::labs(x = 'X label', y = 'Y label') +
  ggplot2::theme(
    axis.title.x = element_text(angle = 0, color = 'grey20'),
    axis.title.y = element_text(angle = 90, color = 'grey20'))
#ggpairs(data_ls[,c(8,10:21,23:24)], title="correlogram with ggpairs()")  # takes a minute and looks a bit messy
#landscape_correlations <- pairs(data_ls[,c(8,10:21,23:27)])

#landscape_correlations





### Developed Land Cover vs. Mean Patch Area

ggplot(data = data_ls, aes(x = develop, y = mpa_undev, group = city, color = city, fill = city)) +
  geom_point() +
  #geom_smooth(method = "lm", lwd = 0.5, alpha = 0.1, se = FALSE) +    # se = TRUE or FALSE are both interesting
  #gghighlight(city %in% c("phaz")) +
  #scale_color_brewer()+
  labs(x = "Developed Land Cover Proportion", y = "Mean Undeveloped Patch Area")



### Developed Land Cover vs. Patch Density

ggplot(data = data_ls, aes(x = develop, y = pd_undev, group = city, color = city, fill = city)) +
  geom_point() +
  stat_smooth(method = "lm", formula = y ~ x + I(x^2), lwd = 0.5, alpha = 0.1, se = TRUE)+
  #geom_smooth(method = "lm", lwd = 0.5, alpha = 0.1, se = FALSE) +    # se = TRUE or FALSE are both interesting
  #gghighlight(city %in% c("phaz")) +
  #scale_color_brewer()+
  labs(x = "Developed Land Cover Proportion", y = "Undeveloped Patch Density")


### Developed Land Cover vs. Edge Density
ggplot(data = data_ls, aes(x = develop, y = ed_undev, group = city, color = city, fill = city)) +
  geom_point() +
  stat_smooth(method = "lm", formula = y ~ x + I(x^2), lwd = 0.5, alpha = 0.1, se = FALSE)+
  #geom_smooth(method = "lm", lwd = 0.5, alpha = 0.1, se = FALSE) +    # se = TRUE or FALSE are both interesting
  #gghighlight(city %in% c("chil")) +
  #scale_color_brewer()+
  labs(x = "Developed Land Cover Proportion", y = "Undeveloped Edge Density")


### Developed Land Cover vs. Overall Patch Isolation
ggplot(data = data_ls, aes(x = develop, y = enn_mn_undev, color = city)) +
  geom_point() +
  stat_smooth(method = "lm", formula = y ~ x + I(x^2), lwd = 0.7, alpha = 0.1, se = FALSE)+
  #gghighlight(city %in% c("phaz")) +
  labs(x = "Developed Land Cover Proportion", y = "Patch Isolation")


### Developed Land Cover vs. Shannon's Index for Patch Diversity
ggplot(data = data_ls, aes(x = develop, y = sdhi, color = city)) +
  geom_point() +
  stat_smooth(method = "lm", formula = y ~ x + I(x^2), lwd = 0.7, alpha = 0.1, se = FALSE)+
  #gghighlight(city %in% c("phaz")) +
  labs(x = "Developed Land Cover Proportion", y = "Shannon's Diversity Index")


### Developed Land Cover vs. Undeveloped Land Cover Proportion, colored by City
# Interesting how there is what seems to be a perpendicular gradient. Let's see if that corresponds to agriculture

ggplot(data = data_ls, aes(x = develop, y = natural, group = city, color = city, fill = city)) +
  geom_point() +
  geom_smooth(method = "lm", lwd = 0.5, alpha = 0.1, se = FALSE) +    # se = TRUE or FALSE are both interesting
  #gghighlight(city %in% c("phaz")) +
  #scale_color_brewer()+
  labs(x = "Developed Land Cover Proportion", y = "Undeveloped Land Cover Proportion")


### Developed Land Cover vs. Undeveloped Land Cover Proportion, colored by Cropland

ggplot(data = data_ls, aes(x = develop, y = natural, color = cropland)) +
  geom_point()

### Ternary Plot of Land Cover: Developed vs. Undeveloped vs. Cropland
install.packages("ggtern")
library(ggtern)

# can use ggtern() instead of ggplot() + coord_tern()
landcover_ternary <- ggtern(data = data_ls, aes(x = develop, y = natural, z = cropland, color = sdhi)) +
  geom_point() +
  scale_color_viridis()+
  labs(x = "Developed", y = "Undeveloped", z = "Agriculture")

landcover_ternary

### Patch Density vs. Patch Isolation (Undeveloped patches)

ggplot(data = data_ls, aes(x = pd_undev, y = enn_mn_undev, color = city)) +
  geom_point() +
  #stat_smooth(method = "lm", formula = y ~ x + I(x^2), lwd = 0.7, alpha = 0.1, se = FALSE)+
  gghighlight(city %in% c("chil")) +
  labs(x = "Undeveloped Patch Density", y = "Undeveloped Patch Isolation")

```

## Calculate site values for median income data 
```{r}
## INCOME DATA
## median household income data from American Community Survey

Sys.getenv("CENSUS_API_KEY")
# load census API key
census_api_key("e649b78a1d98fe7e1c9ff7039840781976777eb6",
    install = TRUE)
 readRenviron("~/.Renviron")

# load in ACS variables  from 2019 
v19 <- load_variables(2019, "acs5", cache = TRUE)

# load in shapefile of subdivisions  
# with median household income as variable of interest

# for washington 
tractincomeWA <- get_acs(state = "WA", 
                         geography = "tract", 
                         variables = c(medincome="B19013_001"),
                         year = 2019, geometry = TRUE) # need to specify 2015-2019 data 
# since acs now automatically calls 2017-2021 

# cut out everything except king and pierce county from our WA shp 
# specify dplyr because rgdal also has filter fxn 
# do this using the GEOID codes for each county 

tractsKP <- tractincomeWA %>% dplyr::filter(substr(GEOID, 1, 5) 
                                            %in% c("53033", "53053"))

mapview(tractsKP) # looks good

# crop to actual study area 
tractsKP <- st_transform(tractsKP, crs=4326)
tractsKP_crop <- st_crop(tractsKP, c(xmin= -121.7, ymin = 46.7, xmax = -122.8, ymax = 47.8))
mapview(tractsKP_crop)

# write shapefiles for cropped area 
st_write(tractsKP_crop, here("data", "income_maps", "seatac_urban_med_income.shp"),
     append = FALSE)

# now rasterize and calculate 

st_transform(tractsKP_crop, crs = "EPSG:32610")  
template <- rast(ext(tractsKP_crop), resolution=100, crs="EPSG:32610")
rast <- terra::rasterize(vect(tractsKP_crop), template, field = "medincome")

# initialize new col for data
income_dat <- st_drop_geometry(sites) %>%
  dplyr::mutate(medincome = NA_real_)

# set buffer radius
buffer_radius <- 1000

Sys.time()

for (i in 1:nrow(sites)) {
  pt <- sites[i, ]  # iterate through sites 
  
  # create buffer
  buff <- vect(st_transform(pt, crs(rast)))
  buff_terra <- terra::buffer(buff, width = buffer_radius) 
  
  # need to give it a bit extra extent 
  buff_ext <- ext(buff_terra) 
  buff_ext <- ext(c(
    xmin = buff_ext$xmin - 1000,
    xmax = buff_ext$xmax + 1000,
    ymin = buff_ext$ymin - 1000,
    ymax = buff_ext$ymax + 1000))
  buff_terra <- crop(buff_terra, buff_ext)
  
  # crop and mask the raster 
  rast_cropped <- crop(rast, buff_terra)
  rast_masked <- terra::mask(rast_cropped, buff_terra)
  
  # xxtract values within the buffer, calculate mean
  extracted_value <- exact_extract(rast_masked, st_as_sf(buff_terra), fun = "mean", 
                                   weights = "area")
  income_dat$medincome[i] <- extracted_value
  
  # Plot the results
  
  p <- ggplot() +
    geom_raster(rast_cropped, mapping = aes(x = x, y = y, fill = medincome)) +
    #   scale_fill_manual() +
    geom_sf(data = st_as_sf(buff_terra), fill = NA, color = "red", size = 1) +
    geom_sf(data = sites[i,], color = "blue", size = 3) +
    coord_sf(crs = st_crs(rast), datum = st_crs(rast)) +
    labs(title = paste("Site:", i),
         x = "Easting (m)", y = "Northing (m)",
         fill = "Raster Value") +
    theme_minimal()
  
  # Save the plot
  # ggsave(filename = paste0("plots/plot_site_", i, ".png"), plot = p, width = 8, height = 6)
  print(p) 
  Sys.sleep(2)
  print(i)
}

Sys.time()

# Check the final results
print(medincome_dat)

write_csv(medincome_dat, here("data", "covariates", "medincome_dat.csv"))
```

## Calculate site values for NDVI
Code adapted from Gina Rosa Cova and Travis Gallo
```{r}
################################################
# NDVI

# GEE composite code from Gina Rosa Cova
# https://code.earthengine.google.com/3a9b724aa57b64d3c54b30249761db56
# Took ~10 minutes to download 
# 30m resolution

# NDVI Extraction code from Travis Gallo

# load LandSat NDVI raster from GRC GEE code 

ndvi_kp <- raster(here("data", "NDVI_data", "NDVI2020SEWATAWA3038_1.tif")) 

# reproject points to raster crs 
sites <- st_transform(sites, crs = st_crs(ndvi_kp))

# extract the proportion of the buffer that has an NDVI greater than 0.2 (vegetation cover)
# this returns a list, so we can use lapply to calculate the proportion for each site

ndvi_extract <- terra::extract(ndvi_kp, points_wa, buffer = 1000) # in m

# calculate the proportion of a site that is covered in vegetation
prop_ndvi_greater0.5 <- lapply(ndvi_extract, function (x){
  # turn values greater than 0.5 to 1 (these are cells that are covered in vegetation)
  x[which(x > 0.5)] <- 1
  # turn values less than 0.5 to 0 (these are cells that are not vegetation)
  x[which(x <= 0.5)] <- 0
  # proportion of cells that are vegetation
  sum(x, na.rm = TRUE)/length(x) })


# turn list into a vector
prop_veg_5 <- do.call(c, prop_ndvi_greater0.5)
prop_veg_5

# calculate the proportion of a site that is covered in vegetation
prop_ndvi_greater0.6 <- lapply(ndvi_extract, function (x){
  # turn values greater than 0.6 to 1 (these are cells that are covered in vegetation)
  x[which(x > 0.6)] <- 1
  # turn values less than 0.6 to 0 (these are cells that are not vegetation)
  x[which(x <= 0.6)] <- 0
  # proportion of cells that are vegetation
  sum(x, na.rm = TRUE)/length(x) })


# turn list into a vector
prop_veg_6 <- do.call(c, prop_ndvi_greater0.6)
prop_veg_6

# calculate the proportion of a site that is covered in vegetation
prop_ndvi_avg <- lapply(ndvi_extract, function (x){
  mean(x) 
  })

# turn list into a vector
prop_veg_avg <- do.call(c, prop_ndvi_avg)
prop_veg_avg


```

## Combine data 
```{r}
data_export <- cbind(sites, metrics_comp, metrics_conf, prop_veg_avg,
                     prop_veg_6, prop_veg_5)
data_export

data_export <- data_export %>% left_join(medincome_dat, by = c("city", "site")) %>%
  left_Join(housing_dat, by = c("city", "site"))

# Make sure 'city' is a factor
data_export$city <- as.factor(data_export$city)

# add columns combining class areas
data_export <- data_export %>% 
  mutate(
    # all forest types
    for_all = (for_ever_temp + for_ever_taig + for_ever_trop + for_dec_trop + for_dec_temp + for_mix),
    # all shrubland types
    shrub_all = (shrub_trop + shrub_temp + shrub_lich),
    # all grassland types
    grass_all = (grass_trop + grass_temp + grass_lich),
    # all woody vegetation cover types (excluding herbaceous grassland cover)
    veg_woody = (for_ever_temp + for_ever_taig + for_ever_trop + for_dec_trop + for_dec_temp + for_mix + shrub_trop + shrub_temp + shrub_lich),  
    # all vegetation cover types (woody and herbaceous). 'Wetland' does not necessarily represent
    veg_all = (for_ever_temp + for_ever_taig + for_ever_trop + for_dec_trop + for_dec_temp + for_mix + shrub_trop + shrub_temp + shrub_lich + grass_trop + grass_temp + grass_lich),      
    # all natural/undeveloped/minimally-developed land cover classes
    natural = (for_ever_temp + for_ever_taig + for_ever_trop + for_dec_trop + for_dec_temp + for_mix + shrub_trop + shrub_temp + grass_trop + grass_temp + shrub_lich + grass_lich + barren_lich + wetland + barren + ice),
    # anthropogenic land cover types
    develop = (urban + cropland)
  ) %>%
  arrange(city, site)

# make sure the city-site index column is filled
data_export$city_site <- paste(data_export$city, data_export$site, sep = "_")

## export 
write.csv(data_export,  "data/covariates/sitecov_1000m_sewatawa_allsites.csv", row.names = FALSE)


```
